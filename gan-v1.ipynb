{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T13:33:31.295857Z","iopub.execute_input":"2021-08-06T13:33:31.296188Z","iopub.status.idle":"2021-08-06T13:33:31.301248Z","shell.execute_reply.started":"2021-08-06T13:33:31.296158Z","shell.execute_reply":"2021-08-06T13:33:31.300362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:33.134928Z","iopub.execute_input":"2021-08-06T13:33:33.135241Z","iopub.status.idle":"2021-08-06T13:33:33.139455Z","shell.execute_reply.started":"2021-08-06T13:33:33.135211Z","shell.execute_reply":"2021-08-06T13:33:33.138698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n    '''\n    Function for visualizing images: Given a tensor of images, number of images, and\n    size per image, plots and prints the images in an uniform grid.\n    '''\n    image_tensor = (image_tensor + 1) / 2\n    image_unflat = image_tensor.detach().cpu()\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:34.756809Z","iopub.execute_input":"2021-08-06T13:33:34.757118Z","iopub.status.idle":"2021-08-06T13:33:34.762688Z","shell.execute_reply.started":"2021-08-06T13:33:34.757088Z","shell.execute_reply":"2021-08-06T13:33:34.76157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n        super(Generator, self).__init__()\n        self.z_dim = z_dim\n        # Build the neural network\n        self.gen = nn.Sequential(\n            self.make_gen_block(z_dim, hidden_dim * 4),\n            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n            self.make_gen_block(hidden_dim * 2, hidden_dim),\n            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n        )\n\n    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n        if not final_layer:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.ReLU(),\n            )\n        else: # Final Layer\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.Tanh()\n            )\n\n    def unsqueeze_noise(self, noise):\n        return noise.view(len(noise), self.z_dim, 1, 1)\n\n    def forward(self, noise):\n        x = self.unsqueeze_noise(noise)\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:36.726406Z","iopub.execute_input":"2021-08-06T13:33:36.726752Z","iopub.status.idle":"2021-08-06T13:33:36.737065Z","shell.execute_reply.started":"2021-08-06T13:33:36.726719Z","shell.execute_reply":"2021-08-06T13:33:36.735933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_noise(n_samples, z_dim, device='cpu'):\n    return torch.randn(n_samples, z_dim, device=device)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:39.904587Z","iopub.execute_input":"2021-08-06T13:33:39.904935Z","iopub.status.idle":"2021-08-06T13:33:39.909373Z","shell.execute_reply.started":"2021-08-06T13:33:39.904905Z","shell.execute_reply":"2021-08-06T13:33:39.908273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, im_chan=1, hidden_dim=16):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            self.make_disc_block(im_chan, hidden_dim),\n            self.make_disc_block(hidden_dim, hidden_dim * 2),\n            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n        )\n\n    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n        if not final_layer:\n            return nn.Sequential(\n              nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n              nn.BatchNorm2d(output_channels),\n              nn.LeakyReLU(negative_slope=0.2)\n            )\n        else: # Final Layer\n            return nn.Sequential(\n                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n            )\n\n    def forward(self, image):\n        disc_pred = self.disc(image)\n        return disc_pred.view(len(disc_pred), -1)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:41.442658Z","iopub.execute_input":"2021-08-06T13:33:41.443058Z","iopub.status.idle":"2021-08-06T13:33:41.45828Z","shell.execute_reply.started":"2021-08-06T13:33:41.443022Z","shell.execute_reply":"2021-08-06T13:33:41.457334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\nz_dim = 64\ndisplay_step = 500\nbatch_size = 128\n# A learning rate of 0.0002 works well on DCGAN\nlr = 0.0002\nbeta_1 = 0.5 \nbeta_2 = 0.999\ndevice = 'cuda'\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:44.995178Z","iopub.execute_input":"2021-08-06T13:33:44.995485Z","iopub.status.idle":"2021-08-06T13:33:45.000087Z","shell.execute_reply.started":"2021-08-06T13:33:44.995456Z","shell.execute_reply":"2021-08-06T13:33:44.999175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),\n])\n\ndataloader = DataLoader(\n    FashionMNIST('.',download=True, transform=transform),\n    batch_size=batch_size,\n    shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:47.252347Z","iopub.execute_input":"2021-08-06T13:33:47.252691Z","iopub.status.idle":"2021-08-06T13:33:47.284959Z","shell.execute_reply.started":"2021-08-06T13:33:47.252653Z","shell.execute_reply":"2021-08-06T13:33:47.284107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\ndisc = Discriminator().to(device) \ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ndef weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)\ngen = gen.apply(weights_init)\ndisc = disc.apply(weights_init)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:49.954073Z","iopub.execute_input":"2021-08-06T13:33:49.954385Z","iopub.status.idle":"2021-08-06T13:33:49.975089Z","shell.execute_reply.started":"2021-08-06T13:33:49.954352Z","shell.execute_reply":"2021-08-06T13:33:49.974271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 50\ncur_step = 0\nmean_generator_loss = 0\nmean_discriminator_loss = 0\nfor epoch in range(n_epochs):\n    for real, _ in tqdm(dataloader):\n        cur_batch_size = len(real)\n        real = real.to(device)\n\n        ## Update discriminator ##\n        disc_opt.zero_grad()\n        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n        fake = gen(fake_noise)\n        disc_fake_pred = disc(fake.detach())\n        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n        disc_real_pred = disc(real)\n        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n\n        mean_discriminator_loss += disc_loss.item() / display_step\n        disc_loss.backward(retain_graph=True)\n        disc_opt.step()\n\n        ## Update generator ##\n        gen_opt.zero_grad()\n        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n        fake_2 = gen(fake_noise_2)\n        disc_fake_pred = disc(fake_2)\n        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n        gen_loss.backward()\n        gen_opt.step()\n\n        mean_generator_loss += gen_loss.item() / display_step\n\n        ## Visualization code ##\n        if cur_step % display_step == 0 and cur_step > 0:\n            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n            show_tensor_images(fake)\n            show_tensor_images(real)\n            mean_generator_loss = 0\n            mean_discriminator_loss = 0\n        cur_step += 1","metadata":{"execution":{"iopub.status.busy":"2021-08-06T13:33:52.680274Z","iopub.execute_input":"2021-08-06T13:33:52.68058Z","iopub.status.idle":"2021-08-06T13:48:35.831127Z","shell.execute_reply.started":"2021-08-06T13:33:52.68055Z","shell.execute_reply":"2021-08-06T13:48:35.829917Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]}]}